{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Dataset(small) prediction\n",
    "\"\"\"\n",
    "\n",
    "Created on Wed Sep 11 22:28:31 2019\n",
    "\n",
    "@author: MOHSIN AKBAR\n",
    "\n",
    "\n",
    "RF-------92\n",
    "accuracies.mean()\n",
    "Out[4]: 0.8160512427647258\n",
    "\n",
    "accuracies.std()\n",
    "Out[5]: 0.04532380081914776\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Random Forest Classification\n",
    "\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set   \n",
    "dataset_train = pd.read_csv('C:/Users\\MOHSIN AKBAR\\kaggle-titanic\\data/train.csv')\n",
    "\n",
    "''' dataset observation\n",
    "\n",
    "# describe\n",
    "print(dataset_train.describe)\n",
    "# class distribution\n",
    "print(dataset_train.groupby('class').size())\n",
    "\n",
    "\n",
    "\n",
    "# box and whisker plots\n",
    "dataset_train.plot(kind='box', subplots=True, layout=(7,7), sharex=False, sharey=False)\n",
    "plt.show()\n",
    "# histograms\n",
    "dataset_train.hist()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# scatter plot matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(dataset_train)\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "to_drop = ['PassengerId','Name','Ticket','Cabin']\n",
    "dataset_train.drop(columns = to_drop,inplace = True)\n",
    "#dataset_train = pd.DataFrame(dataset_train)\n",
    "X_train = dataset_train.iloc[:, 1:8].values\n",
    "# convert dataframe to object\n",
    "#X_train = pd.DataFrame(X_train)\n",
    "\n",
    "y_train = dataset_train.iloc[:, 0].values\n",
    "\n",
    "# Importing the test set   \n",
    "dataset_test = pd.read_csv('C:/Users\\MOHSIN AKBAR\\kaggle-titanic/data/test.csv')\n",
    "dataset_test.drop(columns = to_drop,inplace = True)\n",
    "\n",
    "X_test = dataset_test.iloc[:,0:7].values\n",
    "# X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer_train = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "imputer_train = imputer_train.fit(X_train[:, 2:3])\n",
    "X_train[:, 2:3] = imputer_train.transform(X_train[:, 2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# filling missing values ------here Embarked feature-------using KNN classification\n",
    "dt = X_train\n",
    "dt = pd.DataFrame(dt)\n",
    "\n",
    "X_train_M = dt.iloc[62:828,0:6].values\n",
    "y_train_M = dt.iloc[62:828,6].values\n",
    "\n",
    "X_test_M = dt.iloc[[61,829],0:6].values\n",
    "y_test_M = dt.iloc[[61,829],6].values\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_M = sc.fit_transform(X_train_M)\n",
    "X_test_M = sc.transform(X_test_M)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelencoder_train_M = LabelEncoder()\n",
    "X_train_M[:, 1] = labelencoder_train_M.fit_transform(X_train_M[:, 1]) \n",
    "labelencoder_train_Mt = LabelEncoder()\n",
    "y_train_M = labelencoder_train_Mt.fit_transform(y_train_M) \n",
    "\n",
    "labelencoder_testT = LabelEncoder()\n",
    "X_test_M[:, 1] = labelencoder_testT.fit_transform(X_test_M[:, 1]) \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier_M = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier_M.fit(X_train_M, y_train_M)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_M = classifier_M.predict(X_test_M)\n",
    "\n",
    "y_train_M =pd.DataFrame(y_train_M)\n",
    "\n",
    "# 2,0-----------S,C-------61,829\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train[61,6] = 'S'\n",
    "X_train[829,6] = 'C'\n",
    "# check values of missing values now\n",
    "# X_train =pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test set missing data\n",
    "imputer_test = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "imputer_test = imputer_test.fit(X_test[:, 2:3])\n",
    "imputer_test = imputer_test.fit(X_test[:, 5:6])\n",
    "\n",
    "X_test[:, 2:3] = imputer_test.transform(X_test[:, 2:3])\n",
    "X_test[:, 5:6] = imputer_test.transform(X_test[:, 5:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'female', 'female',\n",
       "       'male', 'female', 'female', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'female',\n",
       "       'male', 'female', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'female', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'female', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'female', 'female', 'female', 'male', 'female', 'male',\n",
       "       'female', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
       "       'male', 'male', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'female', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'female', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'Q', 'S', 'S', 'S',\n",
       "       'C', 'S', 'Q', 'S', 'C', 'C', 'Q', 'S', 'C', 'S', 'C', 'S', 'S',\n",
       "       'C', 'S', 'S', 'C', 'C', 'Q', 'S', 'Q', 'Q', 'C', 'S', 'S', 'S',\n",
       "       'C', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'C', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'C', 'C', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'C', 'S', 'S', 'C', 'S', 'Q',\n",
       "       'S', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'Q', 'S', 'C', 'S',\n",
       "       'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'C', 'S', 'S',\n",
       "       'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'S', 'S', 'S', 'S', 'Q', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'C', 'Q', 'S', 'Q', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'Q', 'C', 'S', 'S', 'S', 'S', 'Q', 'C', 'S', 'S', 'C', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'C', 'Q', 'S', 'S', 'C', 'Q', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'C', 'S', 'C', 'S',\n",
       "       'Q', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'C', 'Q', 'S', 'S', 'S', 'Q', 'S', 'Q', 'S', 'S', 'S', 'S', 'C',\n",
       "       'S', 'S', 'S', 'Q', 'S', 'C', 'C', 'S', 'S', 'C', 'C', 'S', 'S',\n",
       "       'C', 'Q', 'Q', 'S', 'Q', 'S', 'S', 'C', 'C', 'C', 'C', 'C', 'C',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'Q', 'S', 'S',\n",
       "       'C', 'S', 'S', 'S', 'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'C', 'S', 'C', 'S', 'S', 'S', 'Q', 'Q', 'S', 'C', 'C', 'S',\n",
       "       'Q', 'S', 'C', 'C', 'Q', 'C', 'C', 'S', 'S', 'C', 'S', 'C', 'S',\n",
       "       'C', 'C', 'S', 'C', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'C',\n",
       "       'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'Q', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'Q',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'C', 'S',\n",
       "       'C', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'Q', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'S', 'C', 'C', 'S', 'S', 'S', 'S', 'Q', 'Q', 'S', 'S', 'C', 'S',\n",
       "       'S', 'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'S', 'Q', 'S', 'S',\n",
       "       'S', 'S', 'C', 'C', 'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'C', 'C',\n",
       "       'C', 'S', 'S', 'S', 'C', 'S', 'C', 'S', 'S', 'S', 'S', 'C', 'S',\n",
       "       'S', 'C', 'S', 'S', 'C', 'S', 'Q', 'C', 'S', 'S', 'C', 'C', 'S',\n",
       "       'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'Q', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'C', 'C',\n",
       "       'S', 'S', 'C', 'S', 'S', 'S', 'C', 'S', 'Q', 'S', 'S', 'S', 'S',\n",
       "       'C', 'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'S', 'S',\n",
       "       'S', 'Q', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'C', 'S',\n",
       "       'S', 'S', 'Q', 'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'C', 'S', 'C', 'S', 'S',\n",
       "       'S', 'S', 'S', 'Q', 'Q', 'S', 'S', 'Q', 'S', 'C', 'S', 'C', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'C', 'Q', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'S', 'C', 'S', 'C', 'S', 'S', 'S', 'Q', 'C', 'S', 'C', 'S',\n",
       "       'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'C', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'C', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'Q',\n",
       "       'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'Q', 'Q', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'Q', 'S', 'Q', 'S',\n",
       "       'C', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'C', 'Q', 'S', 'S',\n",
       "       'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'C', 'Q', 'C', 'C', 'S',\n",
       "       'C', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'C', 'S',\n",
       "       'S', 'S', 'C', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S',\n",
       "       'C', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'C', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'Q', 'S', 'S', 'S', 'C', 'Q'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 6]\n",
    "#X_train[61,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 'male', 22.0, ..., 0, 7.25, 'S'],\n",
       "       [1, 'female', 38.0, ..., 0, 71.2833, 'C'],\n",
       "       [3, 'female', 26.0, ..., 0, 7.925, 'S'],\n",
       "       ...,\n",
       "       [3, 'female', 28.0, ..., 2, 23.45, 'S'],\n",
       "       [1, 'male', 26.0, ..., 0, 30.0, 'C'],\n",
       "       [3, 'male', 32.0, ..., 0, 7.75, 'Q']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1, 6])], remainder='passthrough')\n",
    "X_train = columnTransformer.fit_transform(X_train)\n",
    "\n",
    "# avoid dummy var. trap\n",
    "X_train = X_train[:,1:]\n",
    "\n",
    "#X_test = columnTransformer.fit_transform(X_test)\n",
    "columnTransformer_test = ColumnTransformer([('encoder', OneHotEncoder(), [1, 6])], remainder='passthrough')\n",
    "X_test = columnTransformer_test.fit_transform(X_test)\n",
    "X_test = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "\n",
    "'''\n",
    "# execute for visualization\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "'''\n",
    "\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 92, criterion = \"gini\", random_state = 7)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'PassengerId': dataset_test.Id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('K-Titanic-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# probabilities as output\n",
    "y_proba = classifier.predict_proba(X_test)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators': [89,90,91,92,93,94,95]} ]\n",
    "grid_search = GridSearchCV(refit = False,estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           # scoring = ['accuracy','explained_variance','f1'],\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_     \n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "# cv_results = grid_search.cv_results_         # for muti-metric scoring\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "\n",
    "\n",
    "'''    UNCOMMENT PCA section first\n",
    "\n",
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('TiDi(Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_pred\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('TiDi (Test set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
